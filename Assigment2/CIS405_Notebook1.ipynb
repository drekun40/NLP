{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "A1"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "zsh:1: command not found: pip\n"
                    ]
                }
            ],
            "source": [
                "!pip install gensim"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "A2"
            },
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'gensim'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapi\u001b[39;00m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
                    ]
                }
            ],
            "source": [
                "import gensim.downloader as api"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "A3"
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'api' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pretrained_word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
                    ]
                }
            ],
            "source": [
                "pretrained_word2vec_model = api.load(\"word2vec-google-news-300\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A4"
            },
            "outputs": [],
            "source": [
                "pretrained_glove_model = api.load(\"glove-wiki-gigaword-300\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A5"
            },
            "outputs": [],
            "source": [
                "pretrained_fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A6"
            },
            "source": [
                "#1. Data Acquisiton"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A7"
            },
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A8"
            },
            "outputs": [],
            "source": [
                "amazon_df  = pd.read_csv(\"amazon_cells_labelled.txt\",sep='\\t',header=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A9"
            },
            "outputs": [],
            "source": [
                "yelp_df = pd.read_csv(\"yelp_labelled.txt\",sep='\\t', header=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A10"
            },
            "outputs": [],
            "source": [
                "imdb_df = pd.read_csv(\"imdb_labelled.txt\",sep='\\t',header=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A11"
            },
            "outputs": [],
            "source": [
                "#Combining all the datasets into one big dataset\n",
                "master_df = pd.concat([amazon_df,yelp_df,imdb_df])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A12"
            },
            "outputs": [],
            "source": [
                "master_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A13"
            },
            "outputs": [],
            "source": [
                "master_df[1].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A14"
            },
            "source": [
                "#2. Text Cleaning & Pre-processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A15"
            },
            "outputs": [],
            "source": [
                "import spacy\n",
                "nlp = spacy.load(\"en_core_web_sm\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A16"
            },
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A17"
            },
            "outputs": [],
            "source": [
                "def clean_preprocess(text):\n",
                "  #Lowercasing\n",
                "  text = text.lower()\n",
                "  #Removing punctuation and digits\n",
                "  doc = nlp(text)\n",
                "  text = [token.text  for token in doc if (not token.is_punct) and (not token.like_num)]\n",
                "  #Removing stopwords\n",
                "  preprocessed_text = [word for word in text if word not in ENGLISH_STOP_WORDS]\n",
                "  #preprocessed_text = ' '.join(text)#Joining list of word into a sentence\n",
                "  return preprocessed_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A18"
            },
            "outputs": [],
            "source": [
                "master_df[0] = master_df[0].apply(lambda row: clean_preprocess(row))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A19"
            },
            "outputs": [],
            "source": [
                "master_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A20"
            },
            "source": [
                "#3. Text Representation or Feature Engineering (using GloVe and fastText pretrained models)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A21"
            },
            "outputs": [],
            "source": [
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A22"
            },
            "outputs": [],
            "source": [
                "def convert_word_to_vector_w2v(text):\n",
                "  total_vector = []\n",
                "  for row in text:#Iterating each row in the text column of the dataset\n",
                "    count = 0\n",
                "    row_total_vector = np.zeros(300) #initializing with the zeros of the same size as vector\n",
                "    for word in row:#Iterating over each word in a row\n",
                "      if word in pretrained_word2vec_model:\n",
                "        row_total_vector = row_total_vector + pretrained_word2vec_model[word]\n",
                "        count = count + 1\n",
                "    if count != 0:\n",
                "      row_avg_vector = row_total_vector/count\n",
                "      total_vector.append(row_avg_vector)\n",
                "    else:\n",
                "      total_vector.append(np.zeros(300))\n",
                "\n",
                "\n",
                "  return total_vector\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A23"
            },
            "outputs": [],
            "source": [
                "X_vector_w2v = convert_word_to_vector_w2v(master_df[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A24"
            },
            "outputs": [],
            "source": [
                "def convert_word_to_vector_glove(text):\n",
                "  total_vector = []\n",
                "  for row in text:#Iterating each row in the text column of the dataset\n",
                "    count = 0\n",
                "    row_total_vector = np.zeros(300) #initializing with the zeros of the same size as vector\n",
                "    for word in row:#Iterating over each word in a row\n",
                "      if word in pretrained_glove_model:\n",
                "        row_total_vector = row_total_vector + pretrained_glove_model[word]\n",
                "        count = count + 1\n",
                "    if count != 0:\n",
                "      row_avg_vector = row_total_vector/count\n",
                "      total_vector.append(row_avg_vector)\n",
                "    else:\n",
                "      total_vector.append(np.zeros(300))\n",
                "\n",
                "\n",
                "  return total_vector\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A25"
            },
            "outputs": [],
            "source": [
                "X_vector_glove = convert_word_to_vector_glove(master_df[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A26"
            },
            "outputs": [],
            "source": [
                "def convert_word_to_vector_fasttext(text):\n",
                "  total_vector = []\n",
                "  for row in text:#Iterating each row in the text column of the dataset\n",
                "    count = 0\n",
                "    row_total_vector = np.zeros(300) #initializing with the zeros of the same size as vector\n",
                "    for word in row:#Iterating over each word in a row\n",
                "      if word in pretrained_fasttext_model:\n",
                "        row_total_vector = row_total_vector + pretrained_fasttext_model[word]\n",
                "        count = count + 1\n",
                "    if count != 0:\n",
                "      row_avg_vector = row_total_vector/count\n",
                "      total_vector.append(row_avg_vector)\n",
                "    else:\n",
                "      total_vector.append(np.zeros(300))\n",
                "\n",
                "\n",
                "  return total_vector\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A27"
            },
            "outputs": [],
            "source": [
                "X_vector_fasttext = convert_word_to_vector_fasttext(master_df[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A28"
            },
            "source": [
                "#4. Training the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A29"
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A30"
            },
            "outputs": [],
            "source": [
                "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_vector_w2v,master_df[1],random_state=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A31"
            },
            "outputs": [],
            "source": [
                "model_w2v = LogisticRegression()#Defining the M.L. Algorithm\n",
                "model_w2v.fit(X_train_w2v, y_train_w2v) #Training the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A32"
            },
            "outputs": [],
            "source": [
                "X_train_glove, X_test_glove, y_train_glove, y_test_glove = train_test_split(X_vector_glove,master_df[1],random_state=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A33"
            },
            "outputs": [],
            "source": [
                "model_glove = LogisticRegression()#Defining the M.L. Algorithm\n",
                "model_glove.fit(X_train_glove, y_train_glove) #Training the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A34"
            },
            "outputs": [],
            "source": [
                "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_vector_fasttext,master_df[1],random_state=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A35"
            },
            "outputs": [],
            "source": [
                "model_fasttext = LogisticRegression()#Defining the M.L. Algorithm\n",
                "model_fasttext.fit(X_train_ft, y_train_ft) #Training the model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A36"
            },
            "source": [
                "#5. Evaluating the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A37"
            },
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A38"
            },
            "outputs": [],
            "source": [
                "model_w2v.score(X_test_w2v,y_test_w2v)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A39"
            },
            "outputs": [],
            "source": [
                "model_glove.score(X_test_glove,y_test_glove)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A40"
            },
            "outputs": [],
            "source": [
                "model_fasttext.score(X_test_ft,y_test_ft)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "A41"
            },
            "source": [
                "#6. Saving the best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "A42"
            },
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open('sentiment_model.pkl', 'wb') as file:\n",
                "    pickle.dump(model_glove, file)"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
