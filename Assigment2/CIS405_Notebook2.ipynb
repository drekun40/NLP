{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import pickle\n",
                "\n",
                "with open('sentiment_model.pkl', 'rb') as file:\n",
                "    loaded_model = pickle.load(file)"
            ],
            "metadata": {
                "id": "TNh4F5yQdjIL"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import gensim.downloader as api"
            ],
            "metadata": {
                "id": "B1"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "pretrained_glove_model = api.load(\"glove-wiki-gigaword-300\")"
            ],
            "metadata": {
                "id": "B2"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import spacy\n",
                "nlp = spacy.load(\"en_core_web_sm\")"
            ],
            "metadata": {
                "id": "B3"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
            ],
            "metadata": {
                "id": "B4"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def clean_preprocess(text):\n",
                "  #Lowercasing\n",
                "  text = text.lower()\n",
                "  #Removing punctuation and digits\n",
                "  doc = nlp(text)\n",
                "  text = [token.text  for token in doc if (not token.is_punct) and (not token.like_num)]\n",
                "  #Removing stopwords\n",
                "  preprocessed_text = [word for word in text if word not in ENGLISH_STOP_WORDS]\n",
                "  #preprocessed_text = ' '.join(text)#Joining list of word into a sentence\n",
                "  return preprocessed_text"
            ],
            "metadata": {
                "id": "B5"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np"
            ],
            "metadata": {
                "id": "B6"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def convert_word_to_vector(text):\n",
                "  total_vector = []\n",
                "  for row in text:#Iterating each row in the text column of the dataset\n",
                "    count = 0\n",
                "    row_total_vector = np.zeros(300) #initializing with the zeros of the same size as vector\n",
                "    for word in row:#Iterating over each word in a row\n",
                "      if word in pretrained_glove_model:\n",
                "        row_total_vector = row_total_vector + pretrained_glove_model[word]\n",
                "        count = count + 1\n",
                "    if count != 0:\n",
                "      row_avg_vector = row_total_vector/count\n",
                "      total_vector.append(row_avg_vector)\n",
                "    else:\n",
                "      total_vector.append(np.zeros(300))\n",
                "\n",
                "\n",
                "  return total_vector\n"
            ],
            "metadata": {
                "id": "B7"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "review = input(\"Enter a review\")"
            ],
            "metadata": {
                "id": "B8"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "processed_text = clean_preprocess(review)"
            ],
            "metadata": {
                "id": "B9"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "sample_vector = convert_word_to_vector([processed_text])"
            ],
            "metadata": {
                "id": "B10"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "sentiment_score = loaded_model.predict(sample_vector)"
            ],
            "metadata": {
                "id": "B11"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "sentiment_score"
            ],
            "metadata": {
                "id": "B12"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "if sentiment_score[0] == 1:\n",
                "  print(\"The review is Positive\")\n",
                "else:\n",
                "  print(\"The review is Negative\")"
            ],
            "metadata": {
                "id": "B13"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}